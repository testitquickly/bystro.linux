Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2025-09-04T02:32:51+03:00

====== Подключить LLM к IDE ======

[ @ide @llm ]

Это легко, но сперва надо основательно кое-что понять:

* IDE может быть любое, хоть “VS Codе”, хоть его оригинальный аналог [[VSCodium]] — принцип подключения LLM для всех один.

* к IDE подключают конкретные LLM (large language model), а не Искуственный Интеллект.

* для повышения эффективности к IDE надо подключить сразу несколько LLM и переключаться между ними — одна модель сильнее в кодогенеративных предсказаниях (code completition), другая — в анализе кода (rationament), третья тупит чуть меньше, чем четвертая. 

* уже есть много моделей, которые можно запускать через локальный сервер на своём ноуте или на отдельном компьютере в локальной сети, что приносит приватность, бесплатность, постоянную доступность, сохранение широкого контекста и гибкость настроек.

* локальные LLM проигрывают «облачным сервисам» по качеству работы — и потому, что в открытом доступе всегда находятся устаревающие экспериментальные проекты, а не «бесплатная копия действующего ИИ», и потому, что «локальные» LLM работают раздражающе медленно — даже если LLM корректно подключена к IDE и оба работают на том же ноутбуке, всё так медленно, что кажется, что подключения нет — просто невозможно дождаться ответа.

* LLM — это БОЛЬШИЕ файлы, для работы с которыми нужно МНОГО вычислительных ресурсов. Условно нормальный «офисный» ноутбук с этим не справится, завоет и условно игровой ноутбук с мощной видеокартой. На компьютере с сильной GPU нейросеть заработает пошустрее, но и только — «быстрее» не означает «быстро». Логично запускать их на отдельном компьютере, а лучше — на кластере мощных компьютеров. Нейросетям, которые «посильнее в рассуждениях» и больше подходят для работы, нужны ресурсы большого сервера, который кому-то надо постоянно обслуживать. 

* для ускорения можно работать с более «лёгкой» моделью, но более «лёгкие» модели, кхм, слабоваты в возможностях, а общее ускорение получается незначительным. 
 
Понятно, почему ИИ с трудом внедряется в больших компаниях , где локальные LLM нужны для того, чтобы защитить «секреты фирмы» — он же работает раздражающе медленно. Интересы корпорации — это очень важно, но зарплата каждого работника зависит от его личной эффективности, поэтому все начинают предпочитать локальным моделям «chatGTP в браузере» или ИИ через API из внешних сервисов за деньги (даже свои).

А ещё локальная LLM //всегда// работает в IDE медленнее, потому что есть **слой посредников**: в консоли всё работает через сервер ollama → выбранную модель → вывод в консоль. В плагине Continue: VS Code → расширение → JSON-RPC → Continue сервер → запрос в Ollama → обратно в IDE. Каждый слой добавляет задержку, и когда CPU ноутбука занят LLM, эти задержки становятся мучительными. А ещё Continue иногда прогоняет ответ через обработчики, например, проверяет JSON, добавляет подсказки, вставляет в правильное место. 

Итого: 

* для работы нужны облачные — или платные, или бесплатные, но «слабые» — LLM,
* подключить локальную LLM к IDE надо хотя бы для того, чтобы посмотреть, как это работает и помечтать о том, как это когда-то будет работать (когда наступит StarTrek), и подумать о том, как построить адекватную инфраструктуру для локальной LLM.

===== Погасить встроенные подсказки IDE =====

В IDE работают встроенные подсказки названий сущностей по ходу набора (классы, методы, etc). Они все нужны просто потому, что подсказки от IDE «дешевле», чем постоянные обращения к LLM. 

Их можно временно отключить, чтобы убедиться в том, что подсказки приходят только от LLM. 

''Ctrl+Shift+P'' 
''> Preferences: Open Settings (JSON)''

или напрямую редактировать 

'''
~/.config/VSCodium/User/settings.json
'''

Отключить все встроенные в IDE подсказки языка:

* "editor.parameterHints.enabled": false
* "editor.suggestOnTriggerCharacters": false,
* "editor.suggest.showClasses": false,
* "editor.suggest.showFunctions": false,
* "editor.suggest.showMethods": false,
* "editor.suggest.showProperties": false,
* "editor.suggest.showSnippets": false,
* "editor.suggest.showVariables": false,
* "editor.suggest.showWords": false,
* "editor.quickSuggestions": {
	"comments": false,
	"strings": false,
	"other": true },

"other": true — оставить, это нужно LLM.

Включить всё то, что позволяет LLM из Continue показывать свои подсказки прямо в редакторе:

* "editor.inlineSuggest.enabled": true,
* "continue.showInlineTip": true,
* "continue.enableQuickActions": true,

Пример файла:

{{{code: lang="json" linenumbers="True"
{
	"_comment1": "====================================== Editor",
	"editor.autoClosingBrackets": "beforeWhitespace",
	"editor.autoClosingComments": "beforeWhitespace",
	"editor.autoClosingQuotes": "beforeWhitespace",
	"editor.autoIndentOnPaste": true,
	"editor.detectIndentation": true,
	"editor.fontFamily": "'Ysabeau'",
	"editor.fontSize": 15,
	"editor.formatOnPaste": true,
	"editor.formatOnSave": true,
	"editor.inlineSuggest.enabled": true,
	"editor.insertSpaces": false,
	"editor.minimap.renderCharacters": false,
	"editor.minimap.showSlider": "always",
	"editor.mouseWheelZoom": true,
	"editor.tabSize": 4,
	"files.autoSave": "onFocusChange",
	"git.confirmSync": false,
	"terminal.external.linuxExec": "konsole",
	"terminal.integrated.defaultProfile.linux": "bash",
	"terminal.integrated.fontFamily": "Cascadia Code",
	"terminal.integrated.fontSize": 13,
	"terminal.integrated.fontWeight": "normal",
	"terminal.integrated.lineHeight": 1.1,
	"terminal.external.linuxArgs": [
		"--profile astenix"
	],
	"workbench.editor.enablePreview": false,
	"_comment2": "====================================== IDE code completition",
	"editor.parameterHints.enabled": false,
	"editor.suggestOnTriggerCharacters": false,
	"editor.suggest.showClasses": false,
	"editor.suggest.showFunctions": false,
	"editor.suggest.showMethods": false,
	"editor.suggest.showProperties": false,
	"editor.suggest.showSnippets": false,
	"editor.suggest.showVariables": false,
	"editor.suggest.showWords": false,
	"editor.quickSuggestions": {
		"comments": false,
		"strings": false,
		"other": true
	},
	"_comment3": "====================================== Continue (LLM)",
	"continue.enableConsole": true,
	"continue.enableNextEdit": true,
	"continue.enableQuickActions": true,
	"continue.enableTabAutocomplete": true,
	"continue.showInlineTip": true,
	"_comment4": "====================================== Telemetry",
	"continue.telemetryEnabled": false,
	"telemetry.feedback.enabled": false,
	"_comment5": "====================================== Updates",
	"update.enableWindowsBackgroundUpdates": false,
	"update.mode": "manual",
	"workbench.enableExperiments": false,
	"workbench.settings.enableNaturalLanguageSearch": true,
}
}}}

===== Установить плагин Continue =====

Взять файл в формате ''*.vsix'' на https://open-vsx.org/extension/Continue/continue (кнопка Download справа внизу).

''Extensions'' 
''> …'' 
''> Install from VSIX…'' 
''>'' указать файл

Неочевидно, но при его работе/настройке нас будут настырно приглашать завести аккаунт на https://hub.continue.dev, в котором будут храниться все настройки, а в IDE их можно будет автоматически подключать. Это можно не делать, но временами плагин таки будет хотеть туда залогиниться, и таки да, единое место хранения многое упрощает, все модели в IDE будут управляться через настройки одного плагина…

При установке плагина будет автоматически создан каталог с файлами:

''~/.continue/''

Для чистоты эксперимента можно удалить его содержимое (позже все файлы самостоятельно вернутся).

Отдельно убедиться в том, что в каталоге проекта нет скрытого каталога “''.continue''”. Если есть — удалить.

===== Подключить внешнюю LLM =====

	*todo Включить отдельно codestal и qwen для ризонинг и посмотреть, как оно работает.

[[+cloud LLM]]

	*todo Засетапить codestral через LAN - ollama. 
	*todo Рассмотреть то, что предлагал chatGPT про балансировку нагрузки llm на beelink.

[[+self-hosted LLM]]

===== Подключить локальную LLM =====

	*todo Засетапить codestral с localhost через ollama.

[[+localhost LLM]]

===== Включить обратно встроенные подсказки IDE =====

{{{code: lang="json" linenumbers="True"
{
	"_comment1": "====================================== Editor",
	"editor.autoClosingBrackets": "beforeWhitespace",
	"editor.autoClosingComments": "beforeWhitespace",
	"editor.autoClosingQuotes": "beforeWhitespace",
	"editor.autoIndentOnPaste": true,
	"editor.detectIndentation": true,
	"editor.fontFamily": "'Ysabeau'",
	"editor.fontSize": 15,
	"editor.formatOnPaste": true,
	"editor.formatOnSave": true,
	"editor.inlineSuggest.enabled": true,
	"editor.insertSpaces": false,
	"editor.minimap.renderCharacters": false,
	"editor.minimap.showSlider": "always",
	"editor.mouseWheelZoom": true,
	"editor.tabSize": 4,
	"files.autoSave": "onFocusChange",
	"git.confirmSync": false,
	"terminal.external.linuxExec": "konsole",
	"terminal.integrated.defaultProfile.linux": "bash",
	"terminal.integrated.fontFamily": "Cascadia Code",
	"terminal.integrated.fontSize": 13,
	"terminal.integrated.fontWeight": "normal",
	"terminal.integrated.lineHeight": 1.1,
	"terminal.external.linuxArgs": [
		"--profile astenix"
	],
	"workbench.editor.enablePreview": false,
	"_comment2": "====================================== IDE code completition",
	"editor.parameterHints.enabled": true,
	"editor.suggestOnTriggerCharacters": true,
	"editor.suggest.showClasses": true,
	"editor.suggest.showFunctions": true,
	"editor.suggest.showMethods": true,
	"editor.suggest.showProperties": true,
	"editor.suggest.showSnippets": true,
	"editor.suggest.showVariables": true,
	"editor.suggest.showWords": true,
	"editor.quickSuggestions": {
		"comments": true,
		"strings": true,
		"other": true
	},
	"_comment3": "====================================== Continue (LLM)",
	"continue.enableConsole": true,
	"continue.enableNextEdit": true,
	"continue.enableQuickActions": true,
	"continue.enableTabAutocomplete": true,
	"continue.showInlineTip": true,
	"_comment4": "====================================== Telemetry",
	"continue.telemetryEnabled": false,
	"telemetry.feedback.enabled": false,
	"_comment5": "====================================== Updates",
	"update.enableWindowsBackgroundUpdates": false,
	"update.mode": "manual",
	"workbench.enableExperiments": false,
	"workbench.settings.enableNaturalLanguageSearch": true,
}
}}}
