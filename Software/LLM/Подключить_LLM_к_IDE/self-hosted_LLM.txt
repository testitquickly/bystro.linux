Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2025-09-11T21:16:40+03:00

====== self-hosted LLM ======

локально развёрнутая языковая модель (LLM), доступная только внутри корпоративной сети (intranet).

Не каждый выделенный сервер оснащён выделенной видеокартой, поэтому модели будут работать на CPU. Это сразу означает «медленнее», но не так, чтобы критично. Главное то, что всё это можно настраивать — приоритет скорости ответов или их точности.

У меня сервером будет отдельно стоящий слабый офисный Beelink Mini S12 Pro (Intel 12th Gen N100 (4C/4T, up to 3.4GHz), 16GB DDR4, 500GB SSD) с Debian без GUI. В нём нет выделенной GPU, поэтому надо тонко настроить llm-окружение под его производительность.
