Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2024-11-30T21:46:21+02:00

====== Whisper ======

[ @sound @openai @whisper ]

«Whisper» — нейронная сеть для распознавания речи, automatic speech recognition (ASR) от OpenAI. Может преобразовывать аудиофайлы в текст (это называется «транскрибирование»). Работает локально. Опубликована с открытым исходным кодом. Поддерживает множество языков (русский и украинский) под «MIT License».

Описание — https://openai.com/index/whisper/

===== Условности =====

Нейросети в работе вообще прожорливы, на большом количестве файлов с применением «большой» модели гудеть кулерами начнёт даже ноутбук, в котором в принципе нет вентиляторов. Разумно начинать с модели „medium” и переходить на более продвинутую только при явной необходимости. Также из сострадания к ресурсам компьютера разумно придирчиво отбирать, какие аудиофайлы действительно //надо// транскрибировать.

У Whisper есть несколько моделей (натренированные нейросети):

* //tiny// и //base//: работают быстро, но точность распознавания очень, эээ, плохая.
* //small//: малая точность, но работает шустро. 
* //__medium__//: хороший баланс между точностью и скоростью.
* //large//: высокая точность, но требует много ресурсов (сильно разгоняет даже очень мощный процессор). Использовать на большом наборе файлов не надо, после 30 минут транскрибации процессор разгонался до 80 по Цельсию, было стрёмно. Для распознавания голосовых бормоталок в офисных условиях избыточна.
* //turbo//: потребляет меньше ресурсов, чем модель //large//, но заточена под скорость, а не под точность расшифровки.

Модель „small” на момент тестирования весит 461 МБ. Модель „large” [[https://github.com/openai/whisper/blob/main/README.md#available-models-and-languages|потребует]] скачать почти три гигабайта. Позже будет больше.

Каждая модель Whisper перед первым её применением будет автоматически загружена из сети и сохранена в кэше профиля пользователя: ''~/.cache/whisper/'' в файле с расширением ''.pt''

Условная скорость работы:
* wav на один голос, моно, 1 min = 5 Mb, с внятной речью, через модель ''small'' транскрибируется за условные 1 мин 15 сек.
* wav на один голос, моно, 5 min = 25 Mb, с внятной речью, через модель ''small'' транскрибируется за 07 мин 10 сек.
* wav на один голос, моно, 10 min = 50 Mb… и так далее.

===== Предварительная конвертация аудио =====

Whisper может читать mp3, но лучше подать ему файлы PCM (формат WAV) с дискретной частотой 16 кГц. Можно и больше, но для записи голоса это избыточно.

Если файл записан в любом другом формате (от аудио в ''ogg'' или ''mp3'' до видео в ''mp4''), можно сперва конвертировать его через ''ffmpeg'':

''file="''__''ИмяФайла''__''"; ffmpeg -i"$file" -ar 16000 -ac 1 "${file%.*}.wav"''

Если надо конвертировать ВСЕ mp3-файлы в каталоге:

''for file in /''__''INPUT_FOLDER''__''/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "${file%.mp3}.wav"; done''

Может быть удобнее обработать файлы из одного каталога и сохранить сконвертированные файлы //в другом// каталоге:

''for file in /''__''INPUT_FOLDER''__''/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "/''__''OUTPUT_FOLDER''__''/$(basename "${file%.mp3}.wav")"; done''

===== Установить Whisper =====

* [[Debian:Install Software:Whisper]]

===== Обновить Whisper =====

Whisper установлен как пакет Python, поэтому надо поднять виртуальное окружение и там 

Узнать нынешнюю версию

''pip show openai-whisper | grep 'Version'''

Посмотреть, если есть обновления — https://github.com/openai/whisper/releases/latest

Если решено обновлять:

''pip install --upgrade openai-whisper''

Также можно сделать

''pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git''

===== Использовать Whisper =====

Перейти в каталог с уже созданным (при установке Whisper) виртуальным окружением Python:

''cd ~/whisper/''

Активировать виртуальное окружение Python:

''source whisper_env/bin/activate''

Для выхода из виртуального окружения надо выполнить в том же каталоге команду “''deactivate''”.

==== Преобразовать в текст один аудиофайл ====

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium --device cuda''

Если указать ''--device cpu'' — вычисления должно происходить на CPU.

В каталоге, из которого выполняется эта команда, появится несколько файлов с расшифрованным текстом:
*.json
*.srt
*.tsv
*.txt
*.vtt

В *.json записывается какой-то RTF-подобный текст:

''{"text": " \u0441 \u0447\u0435\u0433\u043e \u043e\u0431\u044b\u0447\u043d\u043e \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f…''

В *.txt текст записан очень неудобно для восприятия — сплошным потоком, иногда вообще без знаков препинания.

В *.vtt записан текст в виде формата субтитров WEBVTT (Web Video Text Tracks) — он используется в веб-приложениях и поддерживается HTML5. В файлах *.srt то же самое, только ещё и с нумерацией реплик. В принципе файл *.vtt — самый удобный для восприятия.

Чтобы не создавать множество текстовых файлов, можно указать Whisper нужный формат файла с текстом:

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium --device cuda --output_format vtt''

Если обрабатываемый «АУДИОФАЙЛ.mp3» находится в другом каталоге, то разумно сохранить расшифровку рядом с ним:

'''
FILE="/home/astenix/Аудио/1min.wav"; whisper $FILE --language Russian --model medium --device cuda --output_dir "$(dirname $FILE)" --output_format vtt
'''

Кавычки нужны на случай если в полном пути к файлу будут пробелы.

==== Преобразовать в текст множество аудиофайлов ====

Тут надо
* преобразовать последовательно все аудиофайлы, которые находятся в каталоге ''/home/astenix/Аудио'' 
* и подавить вывод текста в консоль, 
* и оставить уведомление о том, что выполняется очередная задача:

''FOLDER="/home/astenix/transcribere/input"; for FILE in $FOLDER/*.wav; do echo "Выполняется транскрибирование — $FILE"; whisper "$FILE" --language Russian --model medium --device cuda --output_dir "$(dirname "$FILE")" --output_format vtt > /dev/null 2>&1; done; echo -e "\n\tТранскрибирование завершено.\n"''

В переменной FOLDER не надо указывать закрывающий слэш.

==== Как убедиться в том, что Whisper работает на GPU? ====

В случае в видеокартой от Nvidia надо сперва установить драйвера, которые ей нужны, см. [[Debian:Install Software:Nvidia]] и установить в виртуальном окружении Python свежую версию PyTorch, см. [[Debian:Install Software:Whisper]]

Установить утилиту для мониторинга GPU

''sudo apt install nvtop''

После запуска Whisper вызвать в отдельной консоли ''nvtop'', а в другой ''htop'' и смотреть на графики. 

Также можно сделать

''nvidia-smi''

Если в таблице будет строка вроде 

''|    0   N/A  N/A     27061      C   ...ace/whisper/whisper_env/bin/python3     5416MiB'' 

то всё ок.
