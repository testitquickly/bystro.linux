Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2024-12-01T00:30:56+02:00

====== Whisper ======

[ @debian @install @sound @openai @whisper ]

Нужен Python и его virtual environment

''sudo apt install python3.11-venv''

и ещё

''sudo apt install ffmpeg''

Сделать каталог для всего этого дела

''mkdir ~/workspace/Whisper/ && cd ~/workspace/Whisper/''

Создать virtual environment для проекта

''python3 -m venv Whisper_env''

Активировать его

''source Whisper_env/bin/activate''

Для выхода из виртуального окружения надо выполнить в том же каталоге команду ''deactivate''

Важно и неочевидно: нельзя __перемещать__ каталог ''whisper_env'', по новому адресу не поднимется вирутальное окружение. Если очень надо его переместить, то следует пересоздать новый „virtual environment” для проекта в том же каталоге.

Снять файлы Whisper из git и установить Whisper и все зависимости

''pip install git+https://github.com/openai/whisper.git''

==== Если есть видеокарта GPU с CUDA ====

1. 
узнать версию CUDA, совместимую с вашей системой.

''nvidia-smi''

В ответе посмотреть 

''Driver Version: 525.85.12''
''CUDA Version: 12.0''

Драйверы CUDA должны были быть установлены отдельно на этапе установке драйверов для Nvidia.

2. 
установить подходящие драйверы для неё — [[Nvidia]]

3. 
Установить библиотеку PyTorch:

Тут такое дело — драйвера Nvidia и библиотека PyTorch прямо не связаны. Сейчас у меня установлена CUDA 12.6, у PyTorch есть скомпилированные драйвера только для CUDA 12.4 В принципе можно скомпилировать драйвера посвежее самому, но без подготовки заниматься этим вряд ли получится. Поэтому рекомендуется поставить последние доступные драйвера и надеяться на то, что они сработают.

Эту команду надо запускать в виртуальном окружении Python, которое уже поднято для работы Whisper:

''pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124''

Зайти в интерпретатор python

''python3''

Выполнить последовательно

'''
import torch
'''

''print(torch.cuda.is_available())''

В ответ ожидаем ''True''.

Выход по ''Ctrl+D''.

Дальше надеемся, что Whisper в работе будет использовать GPU.

===== Настроить Whisper =====

Whisper нагружает CPU очень агрессивно, на уровне 97-101%, даже если ему выделить только одно ядро процессора. Это разгоняет ВЕСЬ камень до +80°C, независимо от системы его охлаждения. Для компьютера в крупном корпусе это не так, чтобы «ой мама!», но всё-таки… и вентиляторы загудят. А для тесного ноутбука это прям заметно много. 

Можно «замедлить» Whisper комплексно:
* использовать модели tiny или small
* ограничить количество задействованных ядер процессора (3 штуки)
* ограничить число потоков для библиотек нейросети (BLAS, MKL, OpenMP)
* отключить вычисления в формате float16 если расчет происходит только на CPU

Модели Tiny или Small хуже распознают речь, поэтому нет, оставим Medium. Остальные ограничения заметно придушат производительность нейросети, но это означает, что Whisper всего лишь будет работать чуть дольше, и это ок. Важно то, что эти настройки снизили рабочую температуру процессора с +88°C до +70°C. 

==== Работа на CPU ====

У процессора может быть несколько физических ядер (threads), и над ними несколько виртуальных (hyperthreads). В настройке Whisper подразумевается использование //только// физических ядер.

Узнать, сколько всего ядер на процессоре компьютера:

'''
nproc
'''

Пример ответа: ''16''

Узнать, сколько физических ядер: 

''cat /proc/cpuinfo | grep 'core id' | sort -u | wc -l''

или

''grep -m1 'cpu cores' /proc/cpuinfo''

Пример ответа: ''8''

Задать количество используемых физических ядер процессора:

''--threads 3''

=== Ограничить число потоков вычислений ===

Whisper использует PyTorch, который может задействовать BLAS, MKL, OpenMP — технологии для ускорения вычислений в математических и научных задачах. Это ускоряет обработку, но может занять все ядра процессора, вызывая перегрузку.

1. BLAS (Basic Linear Algebra Subprograms) — библиотека базовых операций линейной алгебры (матрицы, векторы).
2. MKL (Math Kernel Library) — библиотека Intel, включает BLAS, LAPACK, FFT и другие алгоритмы.
3. OpenMP (Open Multi-Processing) — API для параллельного выполнения кода на CPU. Позволяет использовать многоядерность для ускорения вычислений.

Проверить их настройки по-умолчанию:

''echo $OPENBLAS_NUM_THREADS; echo $MKL_NUM_THREADS; echo $OMP_NUM_THREADS; echo $NUMEXPR_NUM_THREADS''

Если в ответ пустота, это значит, что Whisper будет использовать их без ограничений.

Можно регулировать многопоточность этих вычислений через объявление количества используемых ядер в четырех переменных, например „''2''”. 

Задать „''1''” для принудительного перевода в режим однопоточности:

'''
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OMP_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
'''

=== Отключить вычисления в формате float16 ===

Это нужно, только если транскрибирование выполняется только на CPU.

Добавить в цепочку настроек Whisper при запуске параметр

''--fp16 False'' 

==== Работа на GPU ====

В случае в видеокартой от Nvidia надо сперва установить драйвера, которые ей нужны, см. [[Nvidia]] и установить в виртуальном окружении Python свежую версию PyTorch, см. [[Whisper]]

Затем установить утилиту для мониторинга GPU

''sudo apt install nvtop''

После запуска Whisper вызвать в отдельной консоли ''nvtop'', а в другой ''htop'' и смотреть на графики. 

Также можно сделать

''nvidia-smi''

Если в таблице будет строка вроде 

''|    0   N/A  N/A     27061      C   ...ace/whisper/whisper_env/bin/python3     5416MiB'' 

то всё ок.

После этого рассмотреть настройки Whisper для CPU (кроме подавления вычислений в формате float16).

===== Обновить Whisper =====

Узнать, если есть обновления — https://github.com/openai/whisper/releases/latest

Whisper установлен как пакет Python, поэтому надо а) поднять виртуальное окружение и уже там б) узнать установленную версию

''pip show openai-whisper | grep 'Version'''

и если решено обновлять, то:

''pip install --upgrade openai-whisper''

Также можно сделать

''pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git''

См. [[Software:Whisper]]
